<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>Debug Sampler · v1</title>
<style>
  :root { color-scheme: dark; }
  body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial; margin:16px; background:#0f1115; color:#fff; }
  video, canvas { width: 480px; max-width: 100%; background:#000; border-radius:10px; }
  .pill { display:inline-block; padding:3px 8px; margin:4px 6px 0 0; border-radius:999px; background:#1f2433; font:12px ui-monospace; }
  #diag { font:12px/1.35 ui-monospace, SFMono-Regular, Menlo, Consolas, monospace; white-space:pre-wrap; color:#cbd5e1; margin-top:8px; max-height:240px; overflow:auto; border:1px solid #222; border-radius:8px; padding:8px; background:#0d1220; }
</style>
<!-- libs (we’ll add face-api later; for now we just prove the loop runs) -->
</head>
<body>
<h2>Debug Sampler (no models yet)</h2>

<div>
  <video id="cam" autoplay muted playsinline></video>
  <canvas id="overlay"></canvas>
</div>

<div>
  <span class="pill">Tick: <span id="tick">0</span></span>
  <span class="pill">pushes: <span id="pushes">0</span></span>
  <span class="pill">samples: <span id="samples">0</span></span>
  <span class="pill">fps: <span id="fps">0</span></span>
</div>

<div id="diag">DIAG:\n</div>

<script>
  const $ = id => document.getElementById(id);
  const cam = $('cam'), canv = $('overlay'), ctx = canv.getContext('2d');
  const tickEl=$('tick'), pushesEl=$('pushes'), samplesEl=$('samples'), fpsEl=$('fps'), diagEl=$('diag');

  const SAMPLE_MS = 150;
  let samplingTimer=null, startedAtMs=null, frames=0, fpsT0=performance.now();
  let tick=0, pushes=0;
  const stream=[]; // we’ll just push placeholder rows

  const diag=(...a)=>{ console.log('[diag]', ...a); diagEl.textContent += a.join(' ') + '\n'; };

  async function startWebcam(){
    const st = await navigator.mediaDevices.getUserMedia({ video:{facingMode:'user', width:{ideal:640}, height:{ideal:480}}, audio:false });
    cam.srcObject = st;
    await cam.play();
    canv.width = cam.videoWidth || 640;
    canv.height = cam.videoHeight || 480;
    diag('Webcam ready', canv.width+'x'+canv.height);
    startSampling();
  }

  function startSampling(){
    if (samplingTimer) clearInterval(samplingTimer);
    stream.length = 0; tick=0; pushes=0; startedAtMs = performance.now();
    samplingTimer = setInterval(sampleOnce, SAMPLE_MS);
    diag('Sampling started');
  }

  function stopSampling(){
    if (samplingTimer){ clearInterval(samplingTimer); samplingTimer=null; diag('Sampling stopped'); }
  }

  function sampleOnce(){
    try{
      tick++; tickEl.textContent = String(tick);

      // 1) always increment pushes first
      pushes++; pushesEl.textContent = String(pushes);

      // 2) draw webcam on canvas so we know this runs
      ctx.clearRect(0,0,canv.width,canv.height);
      ctx.drawImage(cam, 0, 0, canv.width, canv.height);

      // 3) push a simple placeholder sample (no models yet)
      const t = ((performance.now() - startedAtMs)/1000).toFixed(3);
      stream.push({ t:+t, note:'placeholder' });
      samplesEl.textContent = String(stream.length);

      // 4) fps
      frames++; const now = performance.now();
      if (now - fpsT0 > 1000){ fpsEl.textContent = String(frames); frames=0; fpsT0 = now; }
    }catch(e){
      diag('sampleOnce error:', e.message);
    }
  }

  window.addEventListener('error', e => diag('window.onerror:', e.message));

  (async () => {
    try { await startWebcam(); } catch(e){ diag('webcam error:', e.message); alert('Camera error: '+e.message); }
  })();
</script>
</body>
</html>
