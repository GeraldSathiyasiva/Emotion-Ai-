<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>MediaPipe Blendshape Emotions (Web)</title>

  <!-- MediaPipe Tasks Vision bundle (Web) -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/vision_bundle.js" crossorigin="anonymous"></script>

  <style>
    :root { color-scheme: dark; }
    body { margin:0; min-height:100vh; display:flex; flex-direction:column; align-items:center; justify-content:center; background:#0f1115; color:#fff; font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial; }
    #container { position:relative; width:100%; max-width:420px; }
    video { width:100%; border-radius:14px; background:#000; display:block; }
    canvas { position:absolute; inset:0; pointer-events:none; border-radius:14px; }
    #hud { width:100%; max-width:420px; display:flex; align-items:center; justify-content:space-between; gap:10px; margin-top:10px; }
    #status { opacity:.95; }
    #fps { opacity:.7; }
    .chip {
      position:absolute; left:50%; transform:translateX(-50%);
      background:rgba(255,255,255,.12); padding:6px 12px; border-radius:999px;
      font-weight:600; backdrop-filter: blur(6px); box-shadow:0 6px 18px rgba(0,0,0,.2);
    }
    #chipMain { top:10px; }
    #chipSubtle { top:44px; display:none; background:rgba(88,170,255,.18); }
    .row { margin-top:10px; display:flex; gap:8px; align-items:center; }
    button { padding:8px 12px; border:0; border-radius:10px; background:#2a2a2a; color:#fff; cursor:pointer; }
    a { color:#9ad; text-decoration:none; }
  </style>
</head>
<body>
  <div id="container">
    <video id="video" autoplay muted playsinline></video>
    <canvas id="overlay"></canvas>
    <div id="chipMain"   class="chip">üòê Neutral</div>
    <div id="chipSubtle" class="chip">Subtle: ‚Äî</div>
  </div>

  <div id="hud">
    <div id="status">Loading MediaPipe‚Ä¶</div>
    <div id="fps"></div>
  </div>

  <div class="row">
    <button id="recal">Re-calibrate (neutral)</button>
    <button id="perf">Performance: High</button>
  </div>

  <script>
    // ======= CONFIG =======
    const MODEL_ASSET_URL =
      "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/latest/face_landmarker.task"; // official model bundle
    const WASM_ROOT =
      "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm"; // wasm helpers

    let highPerf = true;

    // Emojis (macro + nuance)
    const EMOJI = {
      Neutral:'üòê', Happy:'üòÉ', Sad:'üò¢', Angry:'üò†', Fearful:'üò®', Disgusted:'ü§¢', Surprised:'üòÆ',
      Amused:'üòÑ', Attentive:'üëÄ', Skeptical:'ü§®', Determined:'üò§', Concerned:'üòü', Relaxed:'üôÇ'
    };

    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay');
    const ctx = canvas.getContext('2d');
    const statusEl = document.getElementById('status');
    const fpsEl = document.getElementById('fps');
    const chipMain = document.getElementById('chipMain');
    const chipSubtle = document.getElementById('chipSubtle');
    const btnRecal = document.getElementById('recal');
    const btnPerf = document.getElementById('perf');

    const base = { // calibration baselines (from blendshapes)
      browInnerUp:0, browDown:0, outerBrowUp:0,
      eyesOpen:0, squint:0,
      smile:0, frown:0, lipPress:0, lipCornerDown:0,
      cheekRaise:0, jawOpen:0
    };
    let calibrated = false;

    function showErr(m){ statusEl.textContent = m; statusEl.style.color = '#ff8a8a'; }

    // ======= MediaPipe init =======
    let faceLandmarker; let lastVideoTime = -1;

    async function initMediapipe(){
      const vision = await window.FilesetResolver.forVisionTasks(WASM_ROOT); // wasm/webgpu files
      faceLandmarker = await window.FaceLandmarker.createFromOptions(vision, {
        baseOptions: { modelAssetPath: MODEL_ASSET_URL },
        runningMode: "VIDEO",
        numFaces: 1,
        outputFaceBlendshapes: true,
        outputFacialTransformationMatrixes: false
      });
    }

    async function startCamera(){
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          facingMode:'user',
          width:{ ideal:1280 }, height:{ ideal:720 },
          frameRate: highPerf ? { ideal:60, max:120 } : { ideal:30, max:30 }
        }, audio:false
      });
      video.srcObject = stream;
      await new Promise(res => { if (video.readyState >= 2) res(); else video.onloadedmetadata = () => res(); });
      try { await video.play(); } catch(_) {}
      resizeCanvas();
    }

    function resizeCanvas(){
      const w = video.videoWidth || 640, h = video.videoHeight || 480;
      canvas.width = w; canvas.height = h;
    }
    window.addEventListener('resize', resizeCanvas);
    video.addEventListener('loadeddata', resizeCanvas);

    // ======= Helpers: read blendshapes by name =======
    function toMap(blendshapes){
      const m = {};
      if (!blendshapes?.categories) return m;
      for (const c of blendshapes.categories) m[c.categoryName] = c.score;
      return m;
    }

    // Pick a few robust cues (averaging left/right)
    function cuesFromBlend(m){
      // Brows
      const browInnerUp = m["browInnerUp"]||0;
      const browOuterUp = ((m["browOuterUpLeft"]||0)+(m["browOuterUpRight"]||0))/2;
      const browDown    = ((m["browDownLeft"]||0)+(m["browDownRight"]||0))/2;

      // Eyes
      const eyesWide    = ((m["eyeWideLeft"]||0)+(m["eyeWideRight"]||0))/2;
      const eyeSquint   = ((m["eyeSquintLeft"]||0)+(m["eyeSquintRight"]||0))/2;
      const eyeBlink    = ((m["eyeBlinkLeft"]||0)+(m["eyeBlinkRight"]||0))/2;

      // Mouth
      const smile       = ((m["mouthSmileLeft"]||0)+(m["mouthSmileRight"]||0))/2;
      const frown       = ((m["mouthFrownLeft"]||0)+(m["mouthFrownRight"]||0))/2;
      const lipPress    = m["mouthPressLeft"]||0 + m["mouthPressRight"]||0;
      const lipCornerDown = frown; // alias
      const jawOpen     = m["jawOpen"]||0;
      const cheekRaise  = ((m["cheekPuff"]||0)+(m["cheekSquintLeft"]||0)+(m["cheekSquintRight"]||0))/3;

      // Eyes ‚Äúopen‚Äù proxy: wide ‚Äì blink + (1 - squint)
      const eyesOpen = Math.max(0, eyesWide - eyeBlink + (1 - eyeSquint) * 0.2);

      return { browInnerUp, browOuterUp, browDown, eyesOpen, eyeSquint, smile, frown, lipPress, lipCornerDown, jawOpen, cheekRaise };
    }

    // ======= Calibration (2s neutral) =======
    async function calibrate(){
      statusEl.textContent = 'Calibrating‚Ä¶ relax face for 2s';
      const t0 = performance.now();
      const acc = {};
      let n = 0;

      while (performance.now() - t0 < 2000){
        const res = faceLandmarker.detectForVideo(video, performance.now());
        if (res?.faceBlendshapes?.length){
          const m = toMap(res.faceBlendshapes[0]);
          const c = cuesFromBlend(m);
          for (const [k,v] of Object.entries(c)){ acc[k] = (acc[k]||0) + v; }
          n++;
        }
        await new Promise(r=>requestAnimationFrame(r));
      }
      if (n){
        for (const k of Object.keys(base)) if (acc[k] !== undefined) base[k] = acc[k]/n;
        calibrated = true;
        statusEl.textContent = 'Calibrated. Tracking‚Ä¶';
      } else {
        showErr('Calibration failed ‚Äî ensure your face is visible and try again.');
      }
    }

    // ======= Fusion label from blendshape deltas =======
    function fusedLabel(c){
      const d = {
        browUp:   (c.browInnerUp + c.browOuterUp) - (base.browInnerUp + base.outerBrowUp),
        browDown: (c.browDown - base.browDown),
        eyesOpen: (c.eyesOpen - base.eyesOpen),
        squint:   (c.eyeSquint - base.squint),
        smile:    (c.smile - base.smile),
        frown:    (c.frown - base.frown),
        lipPress: (c.lipPress - base.lipPress),
        cornerDown:(c.lipCornerDown - base.lipCornerDown),
        jawOpen:   (c.jawOpen - base.jawOpen),
        cheek:     (c.cheekRaise - base.cheekRaise)
      };

      const s = {
        Surprised:  2.2*Math.max(0,d.browUp) + 1.8*Math.max(0,d.eyesOpen) + 1.2*Math.max(0,d.jawOpen),
        Amused:     2.4*Math.max(0,d.smile)  + 1.4*Math.max(0,d.squint*-1) + 0.8*Math.max(0,d.cheek),
        Angry:      1.8*Math.max(0,d.browDown)+1.6*Math.max(0,d.lipPress)+0.8*Math.max(0,d.cornerDown),
        Sad:        1.6*Math.max(0,d.cornerDown),
        Fearful:    1.2*Math.max(0,d.eyesOpen) + 0.6*Math.max(0,d.browUp),
        Skeptical:  1.6*Math.max(0,d.browDown) + 0.8*Math.max(0,d.lipPress),
        Determined: 1.2*Math.max(0,d.browDown) + 1.0*Math.max(0,d.lipPress),
        Concerned:  1.4*Math.max(0,d.cornerDown) + 0.6*Math.max(0,d.browUp),
        Relaxed:    0.8*Math.max(0, (base.squint - c.eyeSquint)) + 0.6*Math.max(0, (base.lipPress - c.lipPress))
      };

      let best='Neutral', bestVal=0;
      for (const [k,v] of Object.entries(s)) if (v > bestVal){ best=k; bestVal=v; }

      // small deadzone so labels don‚Äôt flip constantly
      if (bestVal < 0.18) return 'Neutral';
      return best;
    }

    function subtleText(c){
      const cues = [];
      if ((c.browInnerUp + c.browOuterUp) - (base.browInnerUp + base.outerBrowUp) > 0.12) cues.push('Brow ‚Üë');
      if (c.browDown - base.browDown > 0.10) cues.push('Brow ‚Üì');
      if (c.eyesOpen - base.eyesOpen > 0.15) cues.push('Eyes ‚Üë');
      if (c.eyeSquint - base.squint > 0.12) cues.push('Squint');
      if (c.smile - base.smile > 0.12) cues.push('Smile');
      if (c.lipPress - base.lipPress > 0.10) cues.push('Lip press');
      if (c.lipCornerDown - base.lipCornerDown > 0.08) cues.push('Corners ‚Üì');
      if (c.jawOpen - base.jawOpen > 0.10) cues.push('Jaw open');
      return cues;
    }

    // ======= Optional: draw key landmarks (simple) =======
    function drawLandmarks(landmarks){
      ctx.clearRect(0,0,canvas.width,canvas.height);
      if (!landmarks?.length) return;
      ctx.lineWidth = 2; ctx.strokeStyle = "rgba(0,200,255,.9)";
      ctx.fillStyle = "rgba(0,200,255,.9)";
      for (const p of landmarks[0]) {
        ctx.beginPath(); ctx.arc(p.x*canvas.width, p.y*canvas.height, 1.6, 0, Math.PI*2); ctx.fill();
      }
    }

    // ======= Main loop =======
    async function init(){
      try{
        statusEl.textContent = 'Loading model‚Ä¶';
        await initMediapipe();                                  // load bundle + model
        statusEl.textContent = 'Starting camera‚Ä¶';
        await startCamera();

        // Quick warmup to ensure outputs exist, then calibrate
        faceLandmarker.detectForVideo(video, performance.now());
        await calibrate();

        let frames = 0, mark = performance.now();
        function loop(){
          const now = performance.now();
          if (video.currentTime !== lastVideoTime){
            const res = faceLandmarker.detectForVideo(video, now);
            lastVideoTime = video.currentTime;

            if (res){
              drawLandmarks(res.faceLandmarks);
              if (res.faceBlendshapes?.length){
                const m = toMap(res.faceBlendshapes[0]);
                const c = cuesFromBlend(m);
                const label = fusedLabel(c);
                chipMain.textContent = `${EMOJI[label] || 'üôÇ'} ${label}`;
                const cues = subtleText(c);
                if (cues.length){ chipSubtle.style.display='block'; chipSubtle.textContent = 'Subtle: ' + cues.join(', '); }
                else { chipSubtle.style.display='none'; }
                statusEl.textContent = 'Tracking‚Ä¶';
              } else {
                chipSubtle.style.display='none';
                statusEl.textContent = 'Face detected (no blendshapes)';
              }
            }
          }

          // FPS
          frames++; if (now - mark > 1000){ fpsEl.textContent = frames + ' fps'; frames=0; mark=now; }
          requestAnimationFrame(loop);
        }
        loop();
      }catch(err){
        showErr('Init error: ' + (err.message || err));
      }
    }

    btnRecal.onclick = calibrate;
    btnPerf.onclick = () => { highPerf = !highPerf; btnPerf.textContent='Performance: ' + (highPerf?'High':'Normal'); location.reload(); };

    init();
  </script>
</body>
</html>
