<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Emotion Detection Demo</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.9.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
  <style>
    body { margin: 0; display: flex; flex-direction: column; align-items: center; }
    video { width: 100%; max-width: 400px; }
    #emotion { font-size: 2em; margin-top: 10px; }
  </style>
</head>
<body>
  <video id="video" autoplay muted></video>
  <div id="emotion">Loading...</div>

  <script>
    const video = document.getElementById('video');
    const emotionDisplay = document.getElementById('emotion');

    // Load models from face-api.js CDN
    Promise.all([
      faceapi.nets.tinyFaceDetector.loadFromUri('/models'),
      faceapi.nets.faceExpressionNet.loadFromUri('/models')
    ]).then(startVideo);

    function startVideo() {
      navigator.mediaDevices.getUserMedia({ video: { facingMode: "user" } })
        .then(stream => {
          video.srcObject = stream;
        })
        .catch(err => {
          emotionDisplay.innerText = "Error accessing camera: " + err;
        });
    }

    video.addEventListener('play', () => {
      const canvas = faceapi.createCanvasFromMedia(video);
      document.body.append(canvas);
      const displaySize = { width: video.width, height: video.height };
      faceapi.matchDimensions(canvas, displaySize);

      setInterval(async () => {
        const detections = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions()).withFaceExpressions();
        if (detections && detections.expressions) {
          const expressions = detections.expressions;
          const maxEmotion = Object.keys(expressions).reduce((a, b) => expressions[a] > expressions[b] ? a : b);
          emotionDisplay.innerText = `Emotion: ${maxEmotion}`;
          canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
          const resizedDetections = faceapi.resizeResults(detections, displaySize);
          faceapi.draw.drawDetections(canvas, resizedDetections);
          faceapi.draw.drawFaceExpressions(canvas, resizedDetections);
        } else {
          emotionDisplay.innerText = 'No face detected';
          canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
        }
      }, 500);  // Every 0.5 sec (adjust for speed)
    });
  </script>
</body>
</html>
