<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>Emotion Autorun — deviceId camera + 5s test</title>
<meta name="viewport" content="width=device-width,initial-scale=1" />
<style>
  :root { color-scheme: dark; }
  body{background:#0f1115;color:#e5e7eb;font-family:system-ui,Arial;margin:16px}
  video,canvas{border:1px solid #2a2f3d;border-radius:10px;background:#000;max-width:100%}
  #diag{white-space:pre-wrap;font:12px ui-monospace;background:#0b1020;border:1px solid #222;border-radius:10px;padding:10px;height:340px;overflow:auto;margin-top:10px}
  .pill{display:inline-block;padding:2px 8px;background:#1f2433;border-radius:8px;margin-left:8px}
</style>

<script>
/* Early logger */
(function(){
  const Q=[]; window.__diagReady=false; window.__diagQ=Q;
  window.diag=function(){ const s=[...arguments].join(' '); console.log('[diag]',s);
    if(!window.__diagReady){Q.push(s);return;}
    const el=document.getElementById('diag'); if(el){ el.textContent+=s+'\n'; el.scrollTop=el.scrollHeight; }
  };
  window.addEventListener('error', e=>diag(`JS ERROR: ${e.message} @ ${e.filename}:${e.lineno}`));
  window.addEventListener('unhandledrejection', e=>diag(`Promise REJECTION: ${e.reason?.message||e.reason}`));
  diag('BOOT: inline logger alive');
})();
</script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.18.0/dist/tf.min.js?v=dev"
        onload="diag('CDN: tfjs loaded')" onerror="diag('CDN: tfjs **FAILED** to load')"></script>
<script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js?v=dev"
        onload="diag('CDN: face-api loaded')" onerror="diag('CDN: face-api **FAILED** to load')"></script>
</head>
<body>
<h2>Autorun 5s Test
  <span class="pill">frames: <span id="pf">0</span></span>
  <span class="pill">faces: <span id="pc">0</span></span>
  <span class="pill">build: deviceid-003</span>
</h2>

<video id="cam" width="640" height="480" autoplay muted playsinline></video>
<canvas id="ov" width="640" height="480"></canvas>
<div id="diag">DIAG:\n</div>

<script>
/* Make DIAG live */
window.__diagReady=true; if(Array.isArray(window.__diagQ)){ window.__diagQ.forEach(s=>diag(s)); window.__diagQ.length=0; }

(async ()=>{
  const MODEL_PAGES='https://geraldsathiyasiva.github.io/Emotion-Ai-/models';
  const MODEL_RAW  ='https://raw.githubusercontent.com/GeraldSathiyasiva/Emotion-Ai-/main/models';
  const SAMPLE_MS=250, TEST_MS=5000;

  const cam=document.getElementById('cam');
  const ov=document.getElementById('ov');
  const ctx=ov.getContext('2d',{willReadFrequently:true});
  const pf=document.getElementById('pf'), pc=document.getElementById('pc');

  diag('ENV secure/localhost:', (location.protocol==='https:' || location.hostname==='localhost'));
  diag('UA:', navigator.userAgent);

  // Live permission state (if supported)
  try{
    if(navigator.permissions?.query){
      const p = await navigator.permissions.query({ name: 'camera' });
      diag('Permission (camera):', p.state);
      p.onchange = ()=>diag('Permission changed →', p.state);
    }
  }catch(e){ diag('Permissions API error:', e.message); }

  // Enumerate devices → choose first video input
  let deviceId = null;
  try{
    const devices = await navigator.mediaDevices.enumerateDevices();
    const cams = devices.filter(d=>d.kind==='videoinput');
    diag('Devices video inputs:', cams.length);
    cams.forEach((d,i)=>diag(`  [${i}]`, d.label || '(no label)', d.deviceId ? 'deviceId present' : 'no id'));
    if (cams.length>0) deviceId = cams[0].deviceId;
  }catch(e){ diag('enumerateDevices error:', e.message); }

  // getUserMedia with timeout + fallbacks (prefer deviceId)
  async function gumWithTimeout(constraints, timeoutMs){
    diag('getUserMedia attempt:', JSON.stringify(constraints));
    let timer; const timeout = new Promise((_,rej)=>{ timer=setTimeout(()=>rej(new Error('getUserMedia timeout')), timeoutMs); });
    try{
      const stream = await Promise.race([ navigator.mediaDevices.getUserMedia(constraints), timeout ]);
      clearTimeout(timer); return stream;
    }catch(e){ clearTimeout(timer); throw e; }
  }

  let stream=null;
  const attempts = [
    deviceId ? { video:{ deviceId: { exact: deviceId }, width:{ideal:1280}, height:{ideal:720} }, audio:false } : null,
    deviceId ? { video:{ deviceId: { exact: deviceId } }, audio:false } : null,
    { video:{ facingMode:'user', width:{ideal:1280}, height:{ideal:720} }, audio:false },
    { video:{ facingMode:'user' }, audio:false },
    { video:true, audio:false },
  ].filter(Boolean);

  for (let i=0;i<attempts.length;i++){
    try{
      stream = await gumWithTimeout(attempts[i], 7000);
      break;
    }catch(err){
      diag('getUserMedia FAILED:', err.name || 'Error', '-', err.message || err);
      if (err.name === 'NotAllowedError'){ diag('HINT: Lock icon → Site settings → Camera → Allow, then reload.'); return; }
      if (i === attempts.length-1){ diag('FATAL: No stream obtained.'); return; }
    }
  }

  cam.srcObject=stream; 
  try{ await cam.play(); }catch(e){ diag('video.play error:', e.message); }
  await new Promise(r=>cam.onloadedmetadata=r);
  ov.width=cam.videoWidth||640; ov.height=cam.videoHeight||480;
  diag('Webcam OK @', cam.videoWidth, 'x', cam.videoHeight);

  // Pick model host (Pages → Raw)
  async function probe(base){
    const u=`${base}/tiny_face_detector_model-weights_manifest.json?cb=${Date.now()}`;
    try{ const r=await fetch(u,{cache:'no-store'}); diag('PROBE', u, '→', r.status); return r.ok ? base : null; }
    catch(err){ diag('PROBE ERR', err.message); return null; }
  }
  const MODEL_URL = await probe(MODEL_PAGES) || await probe(MODEL_RAW);
  if(!MODEL_URL){ diag('FATAL: models not reachable'); return; }
  diag('MODEL_URL =', MODEL_URL);

  // Load models
  try{
    if(faceapi?.tf?.setBackend){ try{ await faceapi.tf.setBackend('webgl'); await faceapi.tf.ready(); }catch{} }
    diag('TFJS backend:', (faceapi.tf?.getBackend && faceapi.tf.getBackend()) || 'n/a');
    await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
    await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
    await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);
    diag('MODELS: OK');
  }catch(e){
    diag('FATAL: model load:', e.message); return;
  }

  // Helpers
  function drawFrame(){
    ctx.clearRect(0,0,ov.width,ov.height);
    ctx.drawImage(cam,0,0,ov.width,ov.height);
  }
  function luminance(){
    const x=Math.max(0,Math.floor(ov.width/2)-32), y=Math.max(0,Math.floor(ov.height/2)-32);
    const w=Math.min(64,ov.width-x), h=Math.min(64,ov.height-y);
    if(w<=0||h<=0) return 0;
    const d=ctx.getImageData(x,y,w,h).data; let s=0,n=0;
    for(let i=0;i<d.length;i+=4){ s+=0.2126*d[i]+0.7152*d[i+1]+0.0722*d[i+2]; n++; }
    return n? s/n : 0;
  }
  async function detectOnce(videoEl){
    const tries=[
      {inputSize:640,scoreThreshold:0.025},
      {inputSize:512,scoreThreshold:0.025},
      {inputSize:384,scoreThreshold:0.030},
      {inputSize:320,scoreThreshold:0.040},
    ];
    for(const t of tries){
      const res=await faceapi.detectAllFaces(videoEl,new faceapi.TinyFaceDetectorOptions(t)).withFaceLandmarks().withFaceExpressions();
      if(res && res.length) return res[0];
    }
    return null;
  }

  // 5s interval test
  diag('Test starting…');
  let ticks=0, detects=0;
  const t0=performance.now();
  const iv=setInterval(async ()=>{
    try{
      if(performance.now()-t0>=TEST_MS){
        clearInterval(iv);
        diag(`Test done — detections=${detects}/${ticks} | manifest: ${MODEL_URL}/tiny_face_detector_model-weights_manifest.json`);
        return;
      }
      ticks++; pf.textContent=String(ticks);
      drawFrame();
      const Y=luminance();
      let det=null;
      try{ det=await detectOnce(cam); }catch(e){ diag('detectOnce error:', e.message); }
      if(det){
        detects++; pc.textContent=String(detects);
        faceapi.draw.drawDetections(ov,[det]);
        faceapi.draw.drawFaceLandmarks(ov,[det]);
        const e=det.expressions||{};
        diag(`✓ score=${det.detection.score.toFixed(3)} lum=${Y.toFixed(1)} happy=${(e.happy||0).toFixed(2)} neutral=${(e.neutral||0).toFixed(2)}`);
      }else{
        diag(`× no face (lum=${Y.toFixed(1)})`);
      }
    }catch(err){ diag('Tick error:', err?.message||err); }
  }, SAMPLE_MS);
})();
</script>
</body>
</html>
