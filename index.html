<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Webcam Face/Emotion Test</title>
<style>
  body { background:#111; color:#fff; font-family:sans-serif; }
  video, canvas { border:1px solid #444; border-radius:8px; }
  #diag { font-family:monospace; white-space:pre-wrap; background:#000; padding:10px; border-radius:8px; margin-top:10px; height:200px; overflow:auto; }
</style>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.18.0"></script>
<script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2"></script>
</head>
<body>
<h2>Face & Emotion Detection Test</h2>
<video id="cam" width="640" height="480" autoplay muted playsinline></video>
<canvas id="overlay" width="640" height="480"></canvas>
<div id="diag">DIAG:\n</div>

<script>
const MODEL_URL = '/models'; // Adjust to your models path
const cam = document.getElementById('cam');
const overlay = document.getElementById('overlay');
const ctx = overlay.getContext('2d');
const diagEl = document.getElementById('diag');

function diag(msg) {
  console.log(msg);
  diagEl.textContent += msg + '\n';
}

async function startWebcam() {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
    cam.srcObject = stream;
    await cam.play();
    diag('Webcam started');
  } catch (err) {
    diag('Webcam error: ' + err.message);
  }
}

async function loadModels() {
  diag('Loading models...');
  await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
  await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
  await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);
  diag('Models loaded');
}

async function detect() {
  const detections = await faceapi.detectAllFaces(cam, new faceapi.TinyFaceDetectorOptions())
    .withFaceLandmarks()
    .withFaceExpressions();

  ctx.clearRect(0, 0, overlay.width, overlay.height);
  if (detections.length > 0) {
    diag(`Detected ${detections.length} face(s)`);
    faceapi.draw.drawDetections(overlay, detections);
    faceapi.draw.drawFaceLandmarks(overlay, detections);

    const expr = detections[0].expressions;
    diag('Emotions: ' + JSON.stringify(expr, null, 2));
  } else {
    diag('No face detected');
  }
}

(async function init() {
  await startWebcam();
  await loadModels();
  setInterval(detect, 200);
})();
</script>
</body>
</html>
