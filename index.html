<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Emotion Ad Test — PR / AWR / PI · v4.0</title>
  <style>
    :root { color-scheme: dark; }
    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial; margin:16px; background:#0f1115; color:#fff; }
    .row { display:flex; flex-wrap:wrap; gap:14px; align-items:flex-start; }
    .panel { flex:1 1 360px; border:1px solid #222; border-radius:12px; padding:12px; background:#131722; }
    label { display:block; font-weight:600; margin-top:10px; }
    input[type="text"] { width:100%; padding:8px 10px; border-radius:8px; border:1px solid #333; background:#161a26; color:#fff; }
    .btns { display:flex; gap:10px; align-items:center; margin-top:12px; flex-wrap:wrap; position:relative; z-index:5; }
    button { padding:10px 14px; border:0; border-radius:10px; background:#2a2f3d; color:#fff; cursor:pointer; }
    button:disabled { opacity:.55; cursor:not-allowed; }
    video, canvas { width:100%; border-radius:12px; background:#000; }
    .kpi { display:flex; gap:10px; margin-top:10px; }
    .kpi>div { flex:1 1 0; background:#101520; border:1px solid #222; border-radius:10px; padding:10px; text-align:center; }
    .muted { color:#9aa3b2; font-size:12px; }
    .badge { display:inline-block; padding:2px 8px; border-radius:8px; font-size:12px; background:#7c2d12; margin-left:8px; }
    .ok { background:#14532d; }
    #diag { font:12px/1.3 ui-monospace, SFMono-Regular, Menlo, Consolas, monospace; white-space:pre-wrap; margin-top:8px; color:#cbd5e1; }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.18.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
</head>
<body>

<h2>Emotion-Only Ad Test (Webcam → PR / AWR / PI)
  <span id="samplestate" class="badge">IDLE</span>
</h2>

<div class="row">
  <div class="panel" style="flex:1 1 560px;">
    <label>Ad URL (MP4 — HTTPS or repo path like <code>ads/my_ad.mp4</code>)</label>
    <input id="adUrl" type="text" placeholder="ads/my_ad.mp4" />

    <div class="panel" style="margin-top:10px;">
      <b>Brand moment windows (seconds: start,end)</b>
      <label>Logo</label> <input id="logoWin" type="text" value="5,7.5" />
      <label>Packshot</label> <input id="packWin" type="text" value="10,12" />
      <label>CTA</label> <input id="ctaWin" type="text" value="18,21" />
      <div class="muted" style="margin-top:6px;">Rough timings are fine; refine later.</div>
    </div>

    <div class="btns">
      <button id="btnLoadModels">1) Load models</button>
      <button id="btnCam" disabled>2) Start webcam</button>
      <button id="btnPlay" disabled>3) Play & analyze</button>
      <button id="btnTest" disabled>Quick webcam test (10s)</button>
      <button id="btnCSV" disabled>Download CSV</button>
      <button id="btnJSON" disabled>Download JSON</button>
      <span id="status" class="muted">—</span>
    </div>

    <div class="row" style="margin-top:10px;">
      <div style="flex:1 1 380px; position:relative; z-index:1;">
        <video id="ad" controls playsinline></video>
      </div>
      <div style="flex:1 1 220px; position:relative; z-index:1;">
        <video id="cam" autoplay muted playsinline style="width:100%;height:auto;"></video>
        <canvas id="overlay" style="width:100%;height:auto;"></canvas>
        <div class="muted" id="fps">— fps</div>
      </div>
    </div>

    <div class="kpi">
      <div><div class="muted">Positive Recognition</div><div id="kPR">—</div></div>
      <div><div class="muted">Awareness</div><div id="kAWR">—</div></div>
      <div><div class="muted">Purchase Intention</div><div id="kPI">—</div></div>
    </div>

    <div id="diag"></div>
  </div>

  <div class="panel" style="flex:1 1 320px;">
    <b>How it works</b>
    <ul class="muted">
      <li>Click Load models → Start webcam → enter Ad URL → Play & analyze.</li>
      <li>Use “Quick webcam test (10s)” to verify face capture w/o an ad.</li>
      <li>Export CSV/JSON after the ad ends.</li>
    </ul>
  </div>
</div>

<script>
  // -------- Robust MODEL path (auto-detects GitHub Pages subpath) --------
  function inferRepoBase() {
    if (location.hostname.endsWith('github.io')) {
      const seg = location.pathname.split('/').filter(Boolean)[0] || '';
      return seg ? `/${seg}/` : '/';
    }
    return './';
  }
  const BASE = inferRepoBase();
  const MODEL_URL = (location.hostname.endsWith('github.io') ? BASE : './') + 'models';

  const $ = id => document.getElementById(id);
  const log = (...a) => { console.log(...a); const s=$('status'); if(s) s.textContent = a.join(' '); };
  const diag = (...a) => { console.log('[diag]', ...a); const d=$('diag'); if(d){ d.textContent += a.join(' ') + '\n'; } };

  async function probeModel(url, file) {
    const full = `${url.replace(/\/$/,'')}/${file}`;
    log('Probing', full, '…');
    const r = await fetch(full, { cache: 'no-store' });
    if (!r.ok) throw new Error(`Probe failed ${r.status} for ${full}`);
    diag('OK:', full);
    return full;
  }
</script>

<script>
  // -------- Config --------
  const SAMPLE_MS = 150;           // ~6–7 Hz
  const BASELINE_PRE = [2.0, 0.5]; // baseline window [te-2.0, te-0.5]
  const RESP_DUR = 2.0;            // response window [te, te+2.0]

  // -------- DOM --------
  const ad = $('ad'), cam = $('cam'), canv = $('overlay'), ctx = canv.getContext('2d');
  const kPR = $('kPR'), kAWR = $('kAWR'), kPI = $('kPI'), statusEl = $('status'), fpsEl = $('fps'), badge=$('samplestate');

  // -------- State --------
  let samplingTimer=null, framesCount=0, fpsT0=performance.now();
  const stream=[];   // rows: {t, att, val, aro, pos, neg, gazeX, gazeY, jitter, face}
  let lastNose=null, startedAtMs=null, webcamReady=false, modelsReady=false;

  // -------- Utils --------
  const clamp=(x,a,b)=>Math.min(b,Math.max(a,x));
  const mean=a=>a.length?a.reduce((x,y)=>x+y,0)/a.length:0;
  const peak=a=>a.length?Math.max(...a):0;
  const stdev=a=>{ if(!a.length) return 0; const m=mean(a); return Math.sqrt(a.reduce((s,x)=>s+(x-m)*(x-m),0)/a.length); };
  const sigmoid=x=>1/(1+Math.exp(-x));
  const parsePair = s => { const [a,b]=(s||'').split(',').map(Number); return [Number(a||0),Number(b||0)]; }
  function setBadge(active){ badge.textContent = active ? 'SAMPLING' : 'IDLE'; badge.className = 'badge ' + (active ? 'ok' : ''); }

  // -------- Feature helpers --------
  function eyeAspectRatio(p, ids){
    const v = (p[ids[1]].y - p[ids[5]].y + p[ids[2]].y - p[ids[4]].y)/2;
    const h = (p[ids[3]].x - p[ids[0]].x);
    return Math.max(0, v/(Math.abs(h)+1e-5));
  }
  function featuresFromLandmarks(det){
    const p = det.landmarks.positions;
    const earL = eyeAspectRatio(p,[36,37,38,39,40,41]);
    const earR = eyeAspectRatio(p,[42,43,44,45,46,47]);
    const eyesOpen = clamp((earL+earR)/2 * 12, 0, 1);

    const nose = p[30], left=p[2], right=p[14], top=p[27], bottom=p[8];
    const cx=(left.x+right.x)/2, cy=(top.y+bottom.y)/2;
    const yaw  = clamp((nose.x-cx)/(Math.abs(right.x-left.x)+1e-5), -0.6, 0.6);
    const pitch= clamp((nose.y-cy)/(Math.abs(bottom.y-top.y)+1e-5), -0.6, 0.6);

    const gazeX = clamp(0.5 + yaw * -0.9, 0, 1);
    const gazeY = clamp(0.5 + pitch *  0.9, 0, 1);

    let jitter=0; if (lastNose) jitter=Math.hypot(nose.x-lastNose.x, nose.y-lastNose.y);
    lastNose = {x:nose.x,y:nose.y};

    return { eyesOpen, gazeX, gazeY, jitter };
  }
  function valenceFromExpr(e){
    const pos = e.happy||0, neg=(e.angry||0)+(e.sad||0)+(e.disgusted||0);
    return clamp(pos - neg, -1, 1);
  }
  function arousalFromExpr(e){
    const act = (e.surprised||0) + (e.fearful||0) + (e.angry||0) + (e.happy||0)*0.5;
    return clamp(act, 0, 1);
  }
  const attentionScore = eyesOpen => clamp(eyesOpen,0,1);

  // -------- Windows / deltas --------
  function windowSlice(t0,t1){ return stream.filter(r=>r.t>=t0 && r.t<t1); }
  function windowStats(t0,t1,key){
    const rows = windowSlice(t0,t1);
    const arr = rows.map(r=>r[key]);
    return { mean: mean(arr), peak: peak(arr), std: stdev(arr) };
  }
  function deltaFeature(te, key){
    const base0 = te - BASELINE_PRE[0], base1 = te - BASELINE_PRE[1];
    const base = windowStats(base0, base1, key);
    const resp = windowStats(te, te + RESP_DUR, key);
    return { dMean: resp.mean - base.mean, dPeak: resp.peak - base.peak, base, resp };
  }

  // -------- KPI scoring (no ROI) --------
  function engagementIndexSimple(t0, dur){
    const eyes = windowStats(t0, t0+dur, 'att').mean;
    const jit = stdev(windowSlice(t0, t0+dur).map(r=>r.jitter));
    const jitterN = Math.max(0, 1 - (jit/2.0));
    return 0.7*eyes + 0.3*jitterN;
  }
  function computeKPIs(winLogo, winPack, winCTA){
    const tLogo = winLogo[0], tPack = winPack[0], tCTA = winCTA[0];

    const dV_logo = deltaFeature(tLogo, 'val');
    const dV_pack = deltaFeature(tPack, 'val');
    const smile_logo_peak = windowStats(tLogo, tLogo+RESP_DUR, 'pos').peak;
    const neg_logo_peak   = windowStats(tLogo, tLogo+RESP_DUR, 'neg').peak;

    const baseAll = windowStats(0, Math.max(0.1, tLogo), 'val');
    const z = (x, m=baseAll.mean, s=0.25)=> s>1e-6 ? (x-m)/s : 0;

    const PR = 100/(1+Math.exp(-(
      0.95*z(dV_logo.dMean) +
      0.55*z(dV_pack.dMean) +
      0.45*z(smile_logo_peak, 0.15, 0.2) -
      0.45*z(neg_logo_peak, 0.1, 0.2)
    )));

    const dA_logo = deltaFeature(tLogo, 'aro').dMean;
    const AWR = 100/(1+Math.exp(-( 0.9*z(dA_logo) )));

    const wCTA = windowStats(tCTA, tCTA+Math.max(2.5, RESP_DUR), 'val');
    const v_cta = wCTA.mean, v_cta_pk = wCTA.peak;
    const eng_cta = engagementIndexSimple(tCTA, Math.max(2.5, RESP_DUR));
    const neg_cta = windowStats(tCTA, tCTA+Math.max(2.5, RESP_DUR), 'neg').peak;

    const PI = 100/(1+Math.exp(-(
      0.85*z(v_cta,  0, 0.3) +
      0.55*z(eng_cta, 0.3, 0.25) +
      0.35*z(v_cta_pk,0.15,0.2) -
      0.55*z(neg_cta, 0.1, 0.2)
    )));
    return { PR:+PR.toFixed(1), AWR:+AWR.toFixed(1), PI:+PI.toFixed(1) };
  }

  // -------- CSV/JSON export --------
  function toCSV(rows){
    const header = ['t','att','val','aro','pos','neg','gazeX','gazeY','jitter','face'];
    const lines = [header.join(',')];
    rows.forEach(r => lines.push([r.t,r.att,r.val,r.aro,r.pos,r.neg,r.gazeX,r.gazeY,r.jitter,r.face].map(x=>typeof x==='number'?x.toFixed(4):x).join(',')));
    return lines.join('\n');
  }
  function download(name, text, type='text/plain'){
    const blob = new Blob([text], {type});
    const a = document.createElement('a');
    a.href = URL.createObjectURL(blob); a.download = name; a.click();
    URL.revokeObjectURL(a.href);
  }

  // -------- Load models --------
  $('btnLoadModels').addEventListener('click', async () => {
    try {
      diag('BASE:', BASE, 'MODEL_URL:', MODEL_URL);
      await probeModel(MODEL_URL, 'tiny_face_detector_model-weights_manifest.json');
      log('Loading TinyFaceDetector…'); await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
      log('Loading FaceLandmark68…');   await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
      log('Loading FaceExpression…');   await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);
      modelsReady = true;
      log('Models loaded ✔  Start webcam next.');
      $('btnCam').disabled = false;
    } catch (e) {
      console.error('Model load error:', e);
      alert(`Model load FAILED:\n${e.message}\n(Open DevTools → Console)`);
      log('Model load FAILED.');
    }
  });

  // -------- Webcam (starts sampling immediately) --------
  $('btnCam').addEventListener('click', async () => {
    try{
      const st = await navigator.mediaDevices.getUserMedia({ video:{facingMode:'user', width:{ideal:640}, height:{ideal:480}}, audio:false });
      cam.srcObject = st;
      await cam.play();
      canv.width = cam.videoWidth || 640; canv.height = cam.videoHeight || 480;
      cam.addEventListener('loadedmetadata', () => {
        canv.width = cam.videoWidth || canv.width;
        canv.height = cam.videoHeight || canv.height;
      });
      webcamReady = true;
      log(`Webcam ready ${canv.width}x${canv.height}.`);
      $('btnPlay').disabled = false;
      $('btnTest').disabled = false;
      startSampling(); // start now so we always capture
    }catch(e){
      log('Camera error:', e.message);
    }
  });

  // -------- Sampling loop --------
  let samplingFpsCount=0, fpsT0=performance.now();
  async function sampleOnce(){
    try{
      const tNow = (isFinite(ad.currentTime) && ad.currentTime>0)
        ? +ad.currentTime.toFixed(3)
        : (startedAtMs ? ((performance.now()-startedAtMs)/1000).toFixed(3) : 0);

      const det = (modelsReady)
        ? await faceapi
            .detectSingleFace(cam, new faceapi.TinyFaceDetectorOptions({inputSize:224, scoreThreshold:0.2}))
            .withFaceLandmarks().withFaceExpressions()
        : null;

      // Draw preview (so overlay isn't black)
      ctx.clearRect(0,0,canv.width,canv.height);
      ctx.drawImage(cam, 0, 0, canv.width, canv.height);

      if (det){
        const res = faceapi.resizeResults(det, { width: canv.width, height: canv.height });
        faceapi.draw.drawDetections(canv, res);
        faceapi.draw.drawFaceLandmarks(canv, res);

        const feats = featuresFromLandmarks(det);
        const e = det.expressions || {};
        const att = attentionScore(feats.eyesOpen);
        const val = valenceFromExpr(e);
        const aro = arousalFromExpr(e);
        const pos = (e.happy||0);
        const neg = (e.angry||0)+(e.sad||0)+(e.disgusted||0);

        stream.push({ t:+tNow, att, val, aro, pos, neg, gazeX:feats.gazeX, gazeY:feats.gazeY, jitter:feats.jitter, face:1 });
        ctx.fillStyle = 'rgba(0,128,0,0.6)'; ctx.fillRect(8,8,120,22);
        ctx.fillStyle = '#fff'; ctx.font = '12px ui-monospace'; ctx.fillText('FACE: yes', 14, 24);
      } else {
        // still push a row so we never get "no samples"
        stream.push({ t:+tNow, att:0, val:0, aro:0, pos:0, neg:0, gazeX:0.5, gazeY:0.5, jitter:0, face:0 });
        ctx.fillStyle = 'rgba(128,0,0,0.6)'; ctx.fillRect(8,8,120,22);
        ctx.fillStyle = '#fff'; ctx.font = '12px ui-monospace'; ctx.fillText('FACE: no', 14, 24);
      }

      // FPS + sample counter
      samplingFpsCount++; const now = performance.now();
      if (now - fpsT0 > 1000){ $('fps').textContent = samplingFpsCount + ' fps'; samplingFpsCount=0; fpsT0 = now; }
      statusEl.textContent = `Recording… samples: ${stream.length}`;
    }catch(e){
      console.debug('sampleOnce error', e);
      diag('sampleOnce error:', e.message);
    }
  }
  function startSampling(){
    stream.length = 0; lastNose = null; startedAtMs = performance.now();
    if (!samplingTimer){ samplingTimer = setInterval(sampleOnce, SAMPLE_MS); setBadge(true); diag('Sampling started'); }
  }
  function stopSampling(){ if (samplingTimer){ clearInterval(samplingTimer); samplingTimer=null; setBadge(false); diag('Sampling stopped'); } }

  // -------- Quick Webcam Test (10s) --------
  $('btnTest').addEventListener('click', async () => {
    if (!webcamReady){ log('Start webcam first'); return; }
    log('Testing webcam capture for ~10s…');
    stream.length = 0;
    const t0 = performance.now();
    const iv = setInterval(()=>{ statusEl.textContent = `Testing… samples: ${stream.length}`; }, 250);
    setTimeout(()=>{ clearInterval(iv); log(`Test done. Samples: ${stream.length}`); }, 10500);
  });

  // -------- Play & Analyze --------
  $('btnPlay').addEventListener('click', async () => {
    const url = $('adUrl').value.trim();
    if (!url){ log('Enter a valid Ad URL (e.g., ads/my_ad.mp4)'); return; }

    ad.src = url;
    try { await ad.play(); } catch(e) { log('Click the video to start playback (autoplay blocked)'); }
    ad.onpause = () => { log('Paused'); };
    ad.onended = () => { stopSampling(); log('Analyzing…'); analyzeAndShow(); };
  });

  function analyzeAndShow(){
    if (!stream.length){ log('No samples captured.'); return; }

    const [logoS, logoE] = parsePair($('logoWin').value);
    const [packS, packE] = parsePair($('packWin').value);
    const [ctaS,  ctaE ] = parsePair($('ctaWin').value);

    const KPIs = computeKPIs([logoS,logoE],[packS,packE],[ctaS,ctaE]);
    $('kPR').textContent  = KPIs.PR.toString();
    $('kAWR').textContent = KPIs.AWR.toString();
    $('kPI').textContent  = KPIs.PI.toString();

    log('Done. Export results below.');
    $('btnCSV').disabled = false; $('btnJSON').disabled = false;
  }

  // -------- Exports --------
  $('btnCSV').addEventListener('click', () => {
    const csv = toCSV(stream);
    download(`frames_${Date.now()}.csv`, csv, 'text/csv');
  });
  $('btnJSON').addEventListener('click', () => {
    const [logoS, logoE] = parsePair($('logoWin').value);
    const [packS, packE] = parsePair($('packWin').value);
    const [ctaS,  ctaE ] = parsePair($('ctaWin').value);
    const KPIs = computeKPIs([logoS,logoE],[packS,packE],[ctaS,ctaE]);
    const out = { meta:{ ts:Date.now(), ad:$('adUrl').value }, kpi: KPIs, frames: stream };
    download(`report_${Date.now()}.json`, JSON.stringify(out,null,2), 'application/json');
  });
</script>
</body>
</html>
